{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjpQQcIhMSzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572d107f-6ec0-4935-f35b-37c437973074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
        "from sklearn.ensemble import RandomForestRegressor  # For the Random Forest regression model\n",
        "import shap\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "import wandb\n",
        "import re\n",
        "\n",
        "pd.set_option('display.expand_frame_repr', False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2nKvfNGzDz2"
      },
      "outputs": [],
      "source": [
        "def save_dataframe(df,file_name):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  file_path = \"/content/drive/My Drive/\"+file_name+\".csv\"\n",
        "  df.to_csv(file_path, index=False)\n",
        "  print(f\"File saved successfully at: {file_path}\")\n",
        "\n",
        "def load_dataframe_from_drive(file_name='Train'):\n",
        "    \"\"\"\n",
        "    Function to load a DataFrame from a Google Drive file path.\n",
        "    \"\"\"\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Load the file from Google Drive\n",
        "    file_path = \"/content/drive/My Drive/\"+file_name+\".csv\"  # Replace with the saved file path\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "def save_model(model,model_name):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  import joblib\n",
        "\n",
        "  # Assuming 'rf_model' is your trained RandomForestRegressor\n",
        "  model_path = '/content/drive/My Drive/'+model_name+'.pkl'\n",
        "  joblib.dump(model, model_path)\n",
        "\n",
        "  print(f\"Model saved at {model_path}\")\n",
        "\n",
        "def load_model(model_name):\n",
        "  import joblib\n",
        "\n",
        "  model = joblib.load('/content/drive/My Drive/'+model_name+'.pkl')\n",
        "  print(\"Model loaded successfully!\")\n",
        "  return model\n",
        "\n",
        "def RMSLE(y_test, y_pred):\n",
        "    '''\n",
        "    RSMLE approximates the percent change\n",
        "    '''\n",
        "    return np.sqrt(np.mean((np.log(y_pred) - np.log(y_test))**2))\n",
        "\n",
        "def RMSE(y_, y_pred_):\n",
        "    '''\n",
        "    RSME\n",
        "    '''\n",
        "    return ((y_ - y_pred_) ** 2).mean() ** 0.5\n",
        "\n",
        "def train_model(df,column_to_predict,test_size_value=0.3,random_state_value=42):\n",
        "    '''\n",
        "    Function to train a Random Forest regression model on a given DataFrame.\n",
        "    '''\n",
        "    print(\"train_model START\")\n",
        "\n",
        "    !wandb login --relogin\n",
        "\n",
        "    # Initialize a new W&B run\n",
        "    wandb.init(\n",
        "        project=\"Predict-heavy-machinery-price\"\n",
        "    )\n",
        "\n",
        "    X = df.drop(columns=[column_to_predict])\n",
        "    y = df[column_to_predict]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_value, random_state=random_state_value)\n",
        "    model = RandomForestRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "    wandb.log({\"mean_squared_error\": mse})\n",
        "    wandb.log({\"Train RMSE\": RMSE(y_train, y_train_pred)})\n",
        "    wandb.log({\"Test RMSE\": RMSE(y_test, y_test_pred)})\n",
        "\n",
        "    # Optional: Log feature importances\n",
        "    importances = model.feature_importances_\n",
        "\n",
        "    # Create a zip of feature names and feature importances\n",
        "    feature_zip = zip(model.feature_names_in_, model.feature_importances_)\n",
        "\n",
        "    # Sort the zip by feature importance in descending order\n",
        "    sorted_feature_zip = sorted(feature_zip, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Print the sorted feature names, importances, and index\n",
        "    for idx, (feat, importance) in enumerate(sorted_feature_zip, 1):\n",
        "        wandb.log({f\"feature_{idx}_{feat}_importance\" : importance})\n",
        "\n",
        "    # Finish the run\n",
        "    wandb.finish()\n",
        "\n",
        "    print(\"RMSE Baseline accuracy:\", y_test.std())\n",
        "    print(\"Train RMSE:\", RMSE(y_train, y_train_pred))\n",
        "    print(\"Test RMSE:\", RMSE(y_test, y_test_pred))\n",
        "\n",
        "    print(\"train_model END\")\n",
        "\n",
        "    return model,(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "\n",
        "def generate_X_Y_params(df,column_to_predict,test_size_value=0.3,random_state_value=42):\n",
        "    X = df.drop(columns=[column_to_predict])\n",
        "    y = df[column_to_predict]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_value, random_state=random_state_value)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def list_unique_values(df, column_name):\n",
        "    \"\"\"\n",
        "    Function to list all unique values in a given column of a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pandas DataFrame\n",
        "    - column_name: Name of the column to find unique values\n",
        "\n",
        "    Returns:\n",
        "    - A list of unique values in the specified column.\n",
        "    \"\"\"\n",
        "    if column_name not in df.columns:\n",
        "        raise ValueError(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
        "\n",
        "    unique_values = df[column_name].unique()\n",
        "    return unique_values\n",
        "\n",
        "\n",
        "# Function to calculate YearMade based on ModelID\n",
        "def calc_YearMade(df, model_id):\n",
        "    valid_years = df.loc[(df['ModelID'] == model_id) & (df['YearMade'] > 1000), 'YearMade']\n",
        "    return int(valid_years.mean()) if not valid_years.empty else 1000  # Default if no valid years exist\n",
        "\n",
        "def update_YearMade(df):\n",
        "  print(\"update_YearMade START\")\n",
        "  # Update YearMade where it is 1000\n",
        "  df.loc[df['YearMade'] == 1000, 'YearMade'] = df.loc[df['YearMade'] == 1000, 'ModelID'].apply(lambda model_id: calc_YearMade(df, model_id))\n",
        "  # Compute the mean excluding rows where YearMade == 1000\n",
        "  mean_yearmade = df.loc[df['YearMade'] != 1000, 'YearMade'].mean()\n",
        "\n",
        "  # Update all rows where YearMade == 1000 with the calculated mean\n",
        "  df.loc[df['YearMade'] == 1000, 'YearMade'] = int(round(mean_yearmade))\n",
        "\n",
        "  print(\"update_YearMade END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def update_auctioneerID(df):\n",
        "  print(\"update_auctioneerID START\")\n",
        "\n",
        "  # Assuming 'df' is your DataFrame\n",
        "  # Fill null values in the 'auctioneerID' column with 100.0\n",
        "  if 'auctioneerID' in df.columns:\n",
        "      df['auctioneerID'] = df['auctioneerID'].fillna(100.0)\n",
        "      #print(\"'auctioneerID' null values filled with 100.0 successfully!\")\n",
        "  #else:\n",
        "  #    print(\"Column 'auctioneerID' does not exist in the DataFrame.\")\n",
        "  print(\"update_auctioneerID END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "def convert_date_columns(df, date_column):\n",
        "    \"\"\"\n",
        "    Convert date column into multiple numeric features like year, month, day, etc.\n",
        "    Handles potential issues like missing date_column or invalid data.\n",
        "    \"\"\"\n",
        "    print(\"convert_date_columns START\")\n",
        "\n",
        "    # Ensure the date_column exists in the DataFrame\n",
        "    if date_column not in df.columns:\n",
        "        raise KeyError(f\"Column '{date_column}' does not exist in the DataFrame.\")\n",
        "\n",
        "    # Convert the column to datetime\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')  # Handle invalid date strings\n",
        "\n",
        "    # Check if any date values are invalid after conversion\n",
        "    if df[date_column].isnull().all():\n",
        "        raise ValueError(f\"All values in '{date_column}' could not be converted to datetime.\")\n",
        "\n",
        "    # Extract date features\n",
        "    df['year'] = df[date_column].dt.year\n",
        "    df['month'] = df[date_column].dt.month\n",
        "    df['day'] = df[date_column].dt.day\n",
        "    df['day_of_week'] = df[date_column].dt.dayofweek\n",
        "    df['is_weekend'] = df['day_of_week'] >= 5  # Saturday=5, Sunday=6\n",
        "\n",
        "    # Drop the original date column\n",
        "    df = df.drop(columns=[date_column])\n",
        "\n",
        "    print(\"convert_date_columns END\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def update_MachineHoursCurrentMeter(df):\n",
        "  print(\"update_MachineHoursCurrentMeter START\")\n",
        "\n",
        "  # Update the 'MachineHoursCurrentMeter' column: replace NaN or 0 with 0\n",
        "  column_name = 'MachineHoursCurrentMeter'\n",
        "\n",
        "  # Check if the column exists\n",
        "  if column_name in df.columns:\n",
        "      df[column_name] = df[column_name].fillna(0)  # Replace NaN with 0\n",
        "      df[column_name] = df[column_name].replace(0, 0)  # Ensure 0 stays 0\n",
        "\n",
        "  print(\"update_MachineHoursCurrentMeter END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "def encode_and_impute(df):\n",
        "    '''\n",
        "    Function to convert categorical columns into category codes\n",
        "    and impute missing values in numerical columns.\n",
        "    '''\n",
        "    print(\"Data Preprocessing START\")\n",
        "\n",
        "    # Handling categorical variables\n",
        "    for col in df.select_dtypes(['object']):\n",
        "        df[col] = df[col].fillna(\"None or Unspecified\").astype('category')\n",
        "\n",
        "    for col in df.select_dtypes(['category']):\n",
        "        df[col] = df[col].cat.codes  # Convert categories to numerical codes\n",
        "\n",
        "    # Handling numerical missing values\n",
        "    for col in df.select_dtypes(['number']):\n",
        "        df[col] = df[col].fillna(df[col].median())  # Fill NaNs with median\n",
        "\n",
        "    print(\"Data Preprocessing END\")\n",
        "    return df\n",
        "\n",
        "def update_col_NaN(df,column_name,update_to):\n",
        "   df[column_name]=df[column_name].fillna(update_to)\n",
        "   return df\n",
        "\n",
        "def clean_column(df, column_name):\n",
        "    \"\"\"\n",
        "    Cleans a column in the DataFrame.\n",
        "    - Replaces 'None or Unspecified' with 1.0.\n",
        "    - Removes double quotes (\") from values.\n",
        "    - Removes the word \"inch\" from values.\n",
        "    - Removes all spaces from values.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame containing the column.\n",
        "        column_name (str): The column to clean.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with cleaned column.\n",
        "    \"\"\"\n",
        "    if column_name not in df.columns:\n",
        "        raise KeyError(f\"Column '{column_name}' not found in DataFrame.\")\n",
        "\n",
        "    df[column_name] = df[column_name].fillna(0.0)\n",
        "\n",
        "    df[column_name] = df[column_name].replace('None or Unspecified', '0.0')\n",
        "\n",
        "    # Function to clean values\n",
        "    def clean_value(value):\n",
        "        str_value = str(value)\n",
        "        str_value = str_value.replace('\"', '')  # Remove double quotes\n",
        "        str_value = str_value.replace('inch', '')  # Remove 'inch'\n",
        "        str_value = str_value.replace(' ', '')  # Remove spaces\n",
        "        return str_value\n",
        "\n",
        "    df[column_name] = df[column_name].apply(clean_value)\n",
        "    df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n",
        "\n",
        "    # Replace 0.0 values with the column median\n",
        "    median_value = df[df[column_name] != 0][column_name].median()\n",
        "    df[column_name] = df[column_name].replace(0.0, median_value)\n",
        "\n",
        "    return df\n",
        "\n",
        "def convert_feet_inches(df, column_name):\n",
        "    \"\"\"\n",
        "    Converts a column containing feet and inches strings to numeric inches.\n",
        "    - Replaces 'None or Unspecified' with \"0' 0\".\n",
        "    - Converts values like \"9' 6\"\" (feet and inches) into total inches.\n",
        "    - Converts the column data type to numeric.\n",
        "    - Replaces 0 values with the column median.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame containing the column.\n",
        "        column_name (str): The column to process.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with cleaned numeric column.\n",
        "    \"\"\"\n",
        "    if column_name not in df.columns:\n",
        "        raise KeyError(f\"Column '{column_name}' not found in DataFrame.\")\n",
        "\n",
        "    # Replace 'None or Unspecified' with \"0' 0\" before processing\n",
        "    df[column_name] = df[column_name].replace('None or Unspecified', \"0' 0\")\n",
        "\n",
        "    # Function to convert feet and inches format to numeric inches\n",
        "    def convert_to_inches(value):\n",
        "        str_value = str(value).strip()\n",
        "\n",
        "        # Match feet and inches pattern\n",
        "        match = re.match(r\"(\\d+)'\\s*(\\d+)?\\\"?\", str_value)\n",
        "        if match:\n",
        "            feet = int(match.group(1))\n",
        "            inches = int(match.group(2)) if match.group(2) else 0\n",
        "            return feet * 12 + inches\n",
        "\n",
        "        return 0  # If format is invalid, default to 0\n",
        "\n",
        "    df[column_name] = df[column_name].apply(convert_to_inches)\n",
        "\n",
        "    # Convert column to numeric\n",
        "    df[column_name] = pd.to_numeric(df[column_name], errors='coerce')\n",
        "\n",
        "    # Replace 0 values with the column median\n",
        "    median_value = df[df[column_name] != 0][column_name].median()\n",
        "    df[column_name] = df[column_name].replace(0, median_value)\n",
        "\n",
        "    return df\n",
        "\n",
        "def process_fidesc_secondary_series(df):\n",
        "    \"\"\"\n",
        "    Iterates over rows and updates fiSecondaryDesc and fiModelSeries based on fiModelDesc and fiBaseModel.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The input DataFrame.\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: The modified DataFrame with updated fiSecondaryDesc and fiModelSeries.\n",
        "    \"\"\"\n",
        "    # Ensure all values are treated as strings to prevent TypeError\n",
        "    df['fiSecondaryDesc'] = df['fiSecondaryDesc'].astype(str)\n",
        "    df['fiModelSeries'] = df['fiModelSeries'].astype(str)\n",
        "\n",
        "    # Get unique values in fiSecondaryDesc (excluding 'nan')\n",
        "    fiSecondaryDesc_unique_values = sorted(\n",
        "        [val for val in df['fiSecondaryDesc'].unique() if val.lower() != 'nan'],\n",
        "        key=len, reverse=True\n",
        "    )\n",
        "\n",
        "    for index in df.index:\n",
        "        fi_model_desc = str(df.at[index, 'fiModelDesc'])  # Convert to string\n",
        "        fi_base_model = str(df.at[index, 'fiBaseModel'])  # Convert to string\n",
        "        fi_secondary_desc = df.at[index, 'fiSecondaryDesc']\n",
        "        fi_model_series = df.at[index, 'fiModelSeries']\n",
        "\n",
        "        # Create fidesc by removing fiBaseModel from fiModelDesc\n",
        "        fidesc = fi_model_desc.replace(fi_base_model, '', 1).strip()\n",
        "\n",
        "        # Skip empty or NaN fidesc\n",
        "        if fidesc.lower() == 'nan' or fidesc == '':\n",
        "            continue\n",
        "\n",
        "        # Update fiSecondaryDesc if fidesc starts with a known unique value\n",
        "        if fi_secondary_desc.lower() == 'nan':  # Only update missing values\n",
        "            for value in fiSecondaryDesc_unique_values:\n",
        "                if fidesc.startswith(value):  # Ensure the match is at the start\n",
        "                    df.at[index, 'fiSecondaryDesc'] = value  # Assign matching unique value\n",
        "                    #fidesc = fidesc[len(value):].strip()  # **Remove the exact match**\n",
        "                    fidesc = fidesc.replace(value,'')\n",
        "                    break  # Stop after the first match\n",
        "\n",
        "        # Ensure fidesc is fully cleaned before updating fiModelSeries\n",
        "        fidesc = fidesc.strip()\n",
        "\n",
        "        # Prevent fiModelSeries from receiving fiSecondaryDesc value again\n",
        "        if fi_model_series.lower() == 'nan' and fidesc and fidesc != df.at[index, 'fiSecondaryDesc']:\n",
        "            # If fiModelSeries still contains fiSecondaryDesc, remove it\n",
        "            if fidesc.startswith(df.at[index, 'fiSecondaryDesc']):\n",
        "                fidesc = fidesc[len(df.at[index, 'fiSecondaryDesc']):].strip()\n",
        "\n",
        "            df.at[index, 'fiModelSeries'] = fidesc  # Assign cleaned fidesc\n",
        "\n",
        "        #print(f\"{fi_model_desc},{fi_base_model},fiSecondaryDesc={df.at[index, 'fiSecondaryDesc']},fiModelSeries={df.at[index, 'fiModelSeries']}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def group_low_frequency_categories(df, threshold_percent=1.0):\n",
        "    \"\"\"\n",
        "    Groups low-frequency categories in all categorical columns based on a dynamic threshold.\n",
        "\n",
        "    Parameters:\n",
        "    df (DataFrame): The input DataFrame.\n",
        "    threshold_percent (float): The percentage (default 1%) of total non-null values below which categories are grouped as \"Other\".\n",
        "\n",
        "    Returns:\n",
        "    DataFrame: The updated DataFrame with grouped low-frequency categories.\n",
        "    \"\"\"\n",
        "    df = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
        "\n",
        "    for col in df.select_dtypes(include=['object']).columns:  # Only process categorical columns\n",
        "        value_counts = df[col].value_counts()  # Get frequency of each category\n",
        "\n",
        "        threshold = df[col].count() * (threshold_percent / 100)  # Dynamic threshold\n",
        "        low_freq_categories = value_counts[value_counts < threshold].index  # Find categories below threshold\n",
        "\n",
        "        if len(low_freq_categories) > 0:  # Only modify if there are low-frequency categories\n",
        "            df[col] = df[col].apply(lambda x: 'Other' if x in low_freq_categories else x)\n",
        "            print(f\"Updated column: {col}, grouped {len(low_freq_categories)} categories into 'Other'\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_dataframe(df_pre:pd.DataFrame):\n",
        "  '''04/02/2025 Start'''\n",
        "  df_pre=update_YearMade(df_pre)\n",
        "  print()\n",
        "\n",
        "  df_pre=update_MachineHoursCurrentMeter(df_pre)\n",
        "  print()\n",
        "\n",
        "  df_pre=update_auctioneerID(df_pre)\n",
        "  print()\n",
        "\n",
        "  #df_pre=update_Enclosure(df_pre)\n",
        "  #print()\n",
        "\n",
        "  df_pre=convert_date_columns(df_pre,'saledate')\n",
        "  print()\n",
        "\n",
        "  #df_pre=encode_all_categories(df_pre)\n",
        "  '''04/02/2025 End'''\n",
        "\n",
        "  '''Start changes 06-02-2025'''\n",
        "  df_pre = process_fidesc_secondary_series(df_pre)\n",
        "\n",
        "  #df_pre=update_col_NaN(df_pre,'UsageBand','None or Unspecified')\n",
        "  #df_pre=convert_feet_inches(df_pre,'Stick_Length')\n",
        "  #df_pre=clean_column(df_pre,'Tire_Size')\n",
        "  df_pre=clean_column(df_pre,'Undercarriage_Pad_Width')\n",
        "  '''End changes 06-02-2025'''\n",
        "\n",
        "  '''Start changes 06-02-2025 0015'''\n",
        "\n",
        "  df_pre=update_col_NaN(df_pre,'ProductSize','None or Unspecified')\n",
        "  df_pre=update_col_NaN(df_pre,'Drive_System','No')\n",
        "  df_pre=update_col_NaN(df_pre,'Stick','None or Unspecified')\n",
        "  df_pre=update_col_NaN(df_pre,'Engine_Horsepower','No')\n",
        "  df_pre=update_col_NaN(df_pre,'Track_Type','None or Unspecified')\n",
        "  df_pre=update_col_NaN(df_pre,'Grouser_Type','None or Unspecified')\n",
        "  df_pre=update_col_NaN(df_pre,'Differential_Type','None or Unspecified')\n",
        "  df_pre=update_col_NaN(df_pre,'Steering_Controls','No')\n",
        "  '''End changes 06-02-2025 0015'''\n",
        "\n",
        "  '''06022025 1620 Grouping Start'''\n",
        "  df_pre = group_low_frequency_categories(df_pre)\n",
        "  '''06022025 1620 Grouping End'''\n",
        "\n",
        "  '''Start changes 05-02-2025 1530'''\n",
        "  df_pre=encode_and_impute(df_pre)\n",
        "  '''End changes 05-02-2025 1530'''\n",
        "\n",
        "  return df_pre\n",
        "\n",
        "def run_test(model):\n",
        "  file_path = \"/content/drive/My Drive/Valid.csv\"  # Replace with the saved file path\n",
        "  df_valid = pd.read_csv(file_path)\n",
        "  df_valid['SalePrice']=None\n",
        "  df_valid=prepare_dataframe(df_valid)\n",
        "  X = df_valid.drop(columns=['SalePrice'])\n",
        "  y = df_valid['SalePrice']\n",
        "  y = model.predict(X)\n",
        "\n",
        "  df_valid.loc[X.index, 'SalePrice'] = y\n",
        "\n",
        "  file_path = \"/content/drive/My Drive/output.csv\"  # Save to Google Drive root\n",
        "  df_valid[['SalesID', 'SalePrice']].to_csv(file_path, index=False)\n",
        "\n",
        "  print(f\"File saved successfully at: {file_path}\")\n",
        "\n",
        "def run_train():\n",
        "  pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "  df=load_dataframe_from_drive()\n",
        "  #df = df.sample(n=10000, random_state=42)\n",
        "  df=prepare_dataframe(df)\n",
        "  model,xs=train_model(df=df,column_to_predict='SalePrice')\n",
        "  #save_dataframe(df,'04022025_df')\n",
        "  #save_model(model,'04022025_model')\n",
        "  #save_dataframe(df,'05022025_df')\n",
        "  #save_model(model,'05022025_model')\n",
        "  #save_dataframe(df,'06022025_df')\n",
        "  #save_model(model,'06022025_model')\n",
        "  #save_dataframe(df,'06022025_1440_df')\n",
        "  #save_model(model,'06022025_1440_model')\n",
        "\n",
        "  '''\n",
        "  df=load_dataframe_from_drive('04022025_df')\n",
        "  model=load_model('04022025_model')\n",
        "  xs=generate_X_Y_params(df,'SalePrice')\n",
        "  '''\n",
        "  return model,xs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhixEKWOyx_k"
      },
      "source": [
        "**RUN CELL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6DE-fzHuyulv",
        "outputId": "97f5dcff-a43e-4875-e7a7-9abca6a385b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting.....\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-6e4d201a662a>:17: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update_YearMade START\n",
            "update_YearMade END\n",
            "\n",
            "update_NaN_To_None_or_Unspecified START\n",
            "update_NaN_To_None_or_Unspecified END\n",
            "\n",
            "update_MachineHoursCurrentMeter START\n",
            "update_MachineHoursCurrentMeter END\n",
            "\n",
            "update_auctioneerID START\n",
            "update_auctioneerID END\n",
            "\n",
            "convert_date_columns START\n",
            "convert_date_columns END\n",
            "\n",
            "Updated column: fiModelDesc, grouped 4994 categories into 'Other'\n",
            "Updated column: fiBaseModel, grouped 1932 categories into 'Other'\n",
            "Updated column: fiSecondaryDesc, grouped 161 categories into 'Other'\n",
            "Updated column: fiModelSeries, grouped 191 categories into 'Other'\n",
            "Updated column: fiModelDescriptor, grouped 128 categories into 'Other'\n",
            "Updated column: fiProductClassDesc, grouped 35 categories into 'Other'\n",
            "Updated column: state, grouped 27 categories into 'Other'\n",
            "Updated column: Drive_System, grouped 1 categories into 'Other'\n",
            "Updated column: Enclosure, grouped 3 categories into 'Other'\n",
            "Updated column: Pad_Type, grouped 2 categories into 'Other'\n",
            "Updated column: Transmission, grouped 4 categories into 'Other'\n",
            "Updated column: Turbocharged, grouped 1 categories into 'Other'\n",
            "Updated column: Blade_Extension, grouped 1 categories into 'Other'\n",
            "Updated column: Blade_Width, grouped 3 categories into 'Other'\n",
            "Updated column: Enclosure_Type, grouped 2 categories into 'Other'\n",
            "Updated column: Engine_Horsepower, grouped 1 categories into 'Other'\n",
            "Updated column: Hydraulics, grouped 6 categories into 'Other'\n",
            "Updated column: Tip_Control, grouped 1 categories into 'Other'\n",
            "Updated column: Tire_Size, grouped 12 categories into 'Other'\n",
            "Updated column: Coupler_System, grouped 1 categories into 'Other'\n",
            "Updated column: Grouser_Tracks, grouped 1 categories into 'Other'\n",
            "Updated column: Hydraulics_Flow, grouped 1 categories into 'Other'\n",
            "Updated column: Stick_Length, grouped 27 categories into 'Other'\n",
            "Updated column: Pattern_Changer, grouped 1 categories into 'Other'\n",
            "Updated column: Grouser_Type, grouped 1 categories into 'Other'\n",
            "Updated column: Backhoe_Mounting, grouped 1 categories into 'Other'\n",
            "Updated column: Blade_Type, grouped 6 categories into 'Other'\n",
            "Updated column: Travel_Controls, grouped 5 categories into 'Other'\n",
            "Updated column: Differential_Type, grouped 3 categories into 'Other'\n",
            "Updated column: Steering_Controls, grouped 3 categories into 'Other'\n",
            "Data Preprocessing START\n",
            "Data Preprocessing END\n",
            "train_model START\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250206_214336-lv3c6a64</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price/runs/lv3c6a64' target=\"_blank\">fiery-sea-27</a></strong> to <a href='https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price' target=\"_blank\">https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price/runs/lv3c6a64' target=\"_blank\">https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price/runs/lv3c6a64</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test RMSE</td><td>▁</td></tr><tr><td>Train RMSE</td><td>▁</td></tr><tr><td>feature_10_ProductGroupDesc_importance</td><td>▁</td></tr><tr><td>feature_11_ProductGroup_importance</td><td>▁</td></tr><tr><td>feature_12_MachineID_importance</td><td>▁</td></tr><tr><td>feature_13_month_importance</td><td>▁</td></tr><tr><td>feature_14_day_importance</td><td>▁</td></tr><tr><td>feature_15_Enclosure_importance</td><td>▁</td></tr><tr><td>feature_16_state_importance</td><td>▁</td></tr><tr><td>feature_17_Pushblock_importance</td><td>▁</td></tr><tr><td>feature_18_fiModelDescriptor_importance</td><td>▁</td></tr><tr><td>feature_19_fiModelSeries_importance</td><td>▁</td></tr><tr><td>feature_1_YearMade_importance</td><td>▁</td></tr><tr><td>feature_20_Transmission_importance</td><td>▁</td></tr><tr><td>feature_21_auctioneerID_importance</td><td>▁</td></tr><tr><td>feature_22_day_of_week_importance</td><td>▁</td></tr><tr><td>feature_23_Ripper_importance</td><td>▁</td></tr><tr><td>feature_24_MachineHoursCurrentMeter_importance</td><td>▁</td></tr><tr><td>feature_25_Drive_System_importance</td><td>▁</td></tr><tr><td>feature_26_Hydraulics_importance</td><td>▁</td></tr><tr><td>feature_27_Blade_Type_importance</td><td>▁</td></tr><tr><td>feature_28_Tire_Size_importance</td><td>▁</td></tr><tr><td>feature_29_UsageBand_importance</td><td>▁</td></tr><tr><td>feature_2_ProductSize_importance</td><td>▁</td></tr><tr><td>feature_30_Ride_Control_importance</td><td>▁</td></tr><tr><td>feature_31_Undercarriage_Pad_Width_importance</td><td>▁</td></tr><tr><td>feature_32_Grouser_Type_importance</td><td>▁</td></tr><tr><td>feature_33_Coupler_importance</td><td>▁</td></tr><tr><td>feature_34_Travel_Controls_importance</td><td>▁</td></tr><tr><td>feature_35_Stick_Length_importance</td><td>▁</td></tr><tr><td>feature_36_Blade_Width_importance</td><td>▁</td></tr><tr><td>feature_37_Thumb_importance</td><td>▁</td></tr><tr><td>feature_38_Differential_Type_importance</td><td>▁</td></tr><tr><td>feature_39_datasource_importance</td><td>▁</td></tr><tr><td>feature_3_fiBaseModel_importance</td><td>▁</td></tr><tr><td>feature_40_Track_Type_importance</td><td>▁</td></tr><tr><td>feature_41_Steering_Controls_importance</td><td>▁</td></tr><tr><td>feature_42_is_weekend_importance</td><td>▁</td></tr><tr><td>feature_43_Forks_importance</td><td>▁</td></tr><tr><td>feature_44_Tip_Control_importance</td><td>▁</td></tr><tr><td>feature_45_Scarifier_importance</td><td>▁</td></tr><tr><td>feature_46_Stick_importance</td><td>▁</td></tr><tr><td>feature_47_Pattern_Changer_importance</td><td>▁</td></tr><tr><td>feature_48_Enclosure_Type_importance</td><td>▁</td></tr><tr><td>feature_49_fiModelDesc_importance</td><td>▁</td></tr><tr><td>feature_4_year_importance</td><td>▁</td></tr><tr><td>feature_50_Engine_Horsepower_importance</td><td>▁</td></tr><tr><td>feature_51_Pad_Type_importance</td><td>▁</td></tr><tr><td>feature_52_Blade_Extension_importance</td><td>▁</td></tr><tr><td>feature_53_Turbocharged_importance</td><td>▁</td></tr><tr><td>feature_54_Grouser_Tracks_importance</td><td>▁</td></tr><tr><td>feature_55_Coupler_System_importance</td><td>▁</td></tr><tr><td>feature_56_Backhoe_Mounting_importance</td><td>▁</td></tr><tr><td>feature_5_SalesID_importance</td><td>▁</td></tr><tr><td>feature_6_ModelID_importance</td><td>▁</td></tr><tr><td>feature_7_fiSecondaryDesc_importance</td><td>▁</td></tr><tr><td>feature_8_Hydraulics_Flow_importance</td><td>▁</td></tr><tr><td>feature_9_fiProductClassDesc_importance</td><td>▁</td></tr><tr><td>mean_squared_error</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test RMSE</td><td>7105.53184</td></tr><tr><td>Train RMSE</td><td>2660.44351</td></tr><tr><td>feature_10_ProductGroupDesc_importance</td><td>0.01925</td></tr><tr><td>feature_11_ProductGroup_importance</td><td>0.01709</td></tr><tr><td>feature_12_MachineID_importance</td><td>0.01633</td></tr><tr><td>feature_13_month_importance</td><td>0.01194</td></tr><tr><td>feature_14_day_importance</td><td>0.01088</td></tr><tr><td>feature_15_Enclosure_importance</td><td>0.00984</td></tr><tr><td>feature_16_state_importance</td><td>0.0095</td></tr><tr><td>feature_17_Pushblock_importance</td><td>0.00803</td></tr><tr><td>feature_18_fiModelDescriptor_importance</td><td>0.00638</td></tr><tr><td>feature_19_fiModelSeries_importance</td><td>0.00584</td></tr><tr><td>feature_1_YearMade_importance</td><td>0.24706</td></tr><tr><td>feature_20_Transmission_importance</td><td>0.00547</td></tr><tr><td>feature_21_auctioneerID_importance</td><td>0.00518</td></tr><tr><td>feature_22_day_of_week_importance</td><td>0.00513</td></tr><tr><td>feature_23_Ripper_importance</td><td>0.00404</td></tr><tr><td>feature_24_MachineHoursCurrentMeter_importance</td><td>0.00357</td></tr><tr><td>feature_25_Drive_System_importance</td><td>0.00349</td></tr><tr><td>feature_26_Hydraulics_importance</td><td>0.00185</td></tr><tr><td>feature_27_Blade_Type_importance</td><td>0.0017</td></tr><tr><td>feature_28_Tire_Size_importance</td><td>0.00159</td></tr><tr><td>feature_29_UsageBand_importance</td><td>0.00126</td></tr><tr><td>feature_2_ProductSize_importance</td><td>0.22867</td></tr><tr><td>feature_30_Ride_Control_importance</td><td>0.00118</td></tr><tr><td>feature_31_Undercarriage_Pad_Width_importance</td><td>0.00102</td></tr><tr><td>feature_32_Grouser_Type_importance</td><td>0.00097</td></tr><tr><td>feature_33_Coupler_importance</td><td>0.00095</td></tr><tr><td>feature_34_Travel_Controls_importance</td><td>0.00094</td></tr><tr><td>feature_35_Stick_Length_importance</td><td>0.00084</td></tr><tr><td>feature_36_Blade_Width_importance</td><td>0.00083</td></tr><tr><td>feature_37_Thumb_importance</td><td>0.00074</td></tr><tr><td>feature_38_Differential_Type_importance</td><td>0.00066</td></tr><tr><td>feature_39_datasource_importance</td><td>0.00064</td></tr><tr><td>feature_3_fiBaseModel_importance</td><td>0.10497</td></tr><tr><td>feature_40_Track_Type_importance</td><td>0.00054</td></tr><tr><td>feature_41_Steering_Controls_importance</td><td>0.0005</td></tr><tr><td>feature_42_is_weekend_importance</td><td>0.00047</td></tr><tr><td>feature_43_Forks_importance</td><td>0.00041</td></tr><tr><td>feature_44_Tip_Control_importance</td><td>0.00034</td></tr><tr><td>feature_45_Scarifier_importance</td><td>0.00032</td></tr><tr><td>feature_46_Stick_importance</td><td>0.00024</td></tr><tr><td>feature_47_Pattern_Changer_importance</td><td>0.00023</td></tr><tr><td>feature_48_Enclosure_Type_importance</td><td>0.00018</td></tr><tr><td>feature_49_fiModelDesc_importance</td><td>0.00012</td></tr><tr><td>feature_4_year_importance</td><td>0.08198</td></tr><tr><td>feature_50_Engine_Horsepower_importance</td><td>5e-05</td></tr><tr><td>feature_51_Pad_Type_importance</td><td>3e-05</td></tr><tr><td>feature_52_Blade_Extension_importance</td><td>3e-05</td></tr><tr><td>feature_53_Turbocharged_importance</td><td>3e-05</td></tr><tr><td>feature_54_Grouser_Tracks_importance</td><td>1e-05</td></tr><tr><td>feature_55_Coupler_System_importance</td><td>0.0</td></tr><tr><td>feature_56_Backhoe_Mounting_importance</td><td>0.0</td></tr><tr><td>feature_5_SalesID_importance</td><td>0.04449</td></tr><tr><td>feature_6_ModelID_importance</td><td>0.0381</td></tr><tr><td>feature_7_fiSecondaryDesc_importance</td><td>0.03401</td></tr><tr><td>feature_8_Hydraulics_Flow_importance</td><td>0.03382</td></tr><tr><td>feature_9_fiProductClassDesc_importance</td><td>0.02628</td></tr><tr><td>mean_squared_error</td><td>50488582.67299</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fiery-sea-27</strong> at: <a href='https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price/runs/lv3c6a64' target=\"_blank\">https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price/runs/lv3c6a64</a><br> View project at: <a href='https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price' target=\"_blank\">https://wandb.ai/sorels-sorel/Predict-heavy-machinery-price</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250206_214336-lv3c6a64/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE Baseline accuracy: 22932.4005340408\n",
            "Train RMSE: 2660.443512828269\n",
            "Test RMSE: 7105.531836041139\n",
            "train_model END\n",
            "Testing...\n",
            "update_YearMade START\n",
            "update_YearMade END\n",
            "\n",
            "update_NaN_To_None_or_Unspecified START\n",
            "update_NaN_To_None_or_Unspecified END\n",
            "\n",
            "update_MachineHoursCurrentMeter START\n",
            "update_MachineHoursCurrentMeter END\n",
            "\n",
            "update_auctioneerID START\n",
            "update_auctioneerID END\n",
            "\n",
            "convert_date_columns START\n",
            "convert_date_columns END\n",
            "\n",
            "Updated column: fiModelDesc, grouped 1729 categories into 'Other'\n",
            "Updated column: fiBaseModel, grouped 767 categories into 'Other'\n",
            "Updated column: fiSecondaryDesc, grouped 67 categories into 'Other'\n",
            "Updated column: fiModelSeries, grouped 96 categories into 'Other'\n",
            "Updated column: fiModelDescriptor, grouped 61 categories into 'Other'\n",
            "Updated column: fiProductClassDesc, grouped 26 categories into 'Other'\n",
            "Updated column: state, grouped 22 categories into 'Other'\n",
            "Updated column: Drive_System, grouped 1 categories into 'Other'\n",
            "Updated column: Enclosure, grouped 1 categories into 'Other'\n",
            "Updated column: Pad_Type, grouped 2 categories into 'Other'\n",
            "Updated column: Transmission, grouped 3 categories into 'Other'\n",
            "Updated column: Turbocharged, grouped 1 categories into 'Other'\n",
            "Updated column: Blade_Extension, grouped 1 categories into 'Other'\n",
            "Updated column: Blade_Width, grouped 3 categories into 'Other'\n",
            "Updated column: Enclosure_Type, grouped 1 categories into 'Other'\n",
            "Updated column: Engine_Horsepower, grouped 1 categories into 'Other'\n",
            "Updated column: Hydraulics, grouped 5 categories into 'Other'\n",
            "Updated column: Tip_Control, grouped 2 categories into 'Other'\n",
            "Updated column: Tire_Size, grouped 10 categories into 'Other'\n",
            "Updated column: Hydraulics_Flow, grouped 1 categories into 'Other'\n",
            "Updated column: Stick_Length, grouped 20 categories into 'Other'\n",
            "Updated column: Pattern_Changer, grouped 1 categories into 'Other'\n",
            "Updated column: Blade_Type, grouped 3 categories into 'Other'\n",
            "Updated column: Travel_Controls, grouped 5 categories into 'Other'\n",
            "Updated column: Differential_Type, grouped 2 categories into 'Other'\n",
            "Updated column: Steering_Controls, grouped 2 categories into 'Other'\n",
            "Data Preprocessing START\n",
            "Data Preprocessing END\n",
            "File saved successfully at: /content/drive/My Drive/output.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-6e4d201a662a>:485: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[56140.   76575.   32952.75 ... 10777.5  13177.5  26462.5 ]' has dtype incompatible with int8, please explicitly cast to a compatible dtype first.\n",
            "  df_valid.loc[X.index, 'SalePrice'] = y\n"
          ]
        }
      ],
      "source": [
        "print('Starting.....')\n",
        "model,xs=run_train()\n",
        "print('Testing...')\n",
        "run_test(model)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}