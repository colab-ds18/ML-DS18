{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hjpQQcIhMSzD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
        "from sklearn.ensemble import RandomForestRegressor  # For the Random Forest regression model\n",
        "import shap\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "import os\n",
        "\n",
        "pd.set_option('display.expand_frame_repr', False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataframe(df,file_name):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  file_path = \"/content/drive/My Drive/\"+file_name+\".csv\"\n",
        "  df.to_csv(file_path, index=False)\n",
        "  print(f\"File saved successfully at: {file_path}\")\n",
        "\n",
        "def load_dataframe_from_drive(file_name='Train'):\n",
        "    \"\"\"\n",
        "    Function to load a DataFrame from a Google Drive file path.\n",
        "    \"\"\"\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Load the file from Google Drive\n",
        "    file_path = \"/content/drive/My Drive/\"+file_name+\".csv\"  # Replace with the saved file path\n",
        "    df = pd.read_csv(file_path)\n",
        "    return df\n",
        "\n",
        "def save_model(model,model_name):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  import joblib\n",
        "\n",
        "  # Assuming 'rf_model' is your trained RandomForestRegressor\n",
        "  model_path = '/content/drive/My Drive/'+model_name+'.pkl'\n",
        "  joblib.dump(model, model_path)\n",
        "\n",
        "  print(f\"Model saved at {model_path}\")\n",
        "\n",
        "def load_model(model_name):\n",
        "  import joblib\n",
        "\n",
        "  model = joblib.load('/content/drive/My Drive/'+model_name+'.pkl')\n",
        "  print(\"Model loaded successfully!\")\n",
        "  return model\n",
        "\n",
        "def RMSLE(y_test, y_pred):\n",
        "    '''\n",
        "    RSMLE approximates the percent change\n",
        "    '''\n",
        "    return np.sqrt(np.mean((np.log(y_pred) - np.log(y_test))**2))\n",
        "\n",
        "def RMSE(y_, y_pred_):\n",
        "    '''\n",
        "    RSME\n",
        "    '''\n",
        "    return ((y_ - y_pred_) ** 2).mean() ** 0.5\n",
        "\n",
        "def train_model(df,column_to_predict,test_size_value=0.3,random_state_value=42):\n",
        "    '''\n",
        "    Function to train a Random Forest regression model on a given DataFrame.\n",
        "    '''\n",
        "    print(\"train_model START\")\n",
        "\n",
        "    X = df.drop(columns=[column_to_predict])\n",
        "    y = df[column_to_predict]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_value, random_state=random_state_value)\n",
        "    model = RandomForestRegressor()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"RMSE Baseline accuracy:\", y_test.std())\n",
        "    print(\"Train RMSE:\", RMSE(y_train, y_train_pred))\n",
        "    print(\"Test RMSE:\", RMSE(y_test, y_test_pred))\n",
        "\n",
        "    print(\"train_model END\")\n",
        "\n",
        "    return model,(X_train, X_test, y_train, y_test)\n",
        "\n",
        "def generate_X_Y_params(df,column_to_predict,test_size_value=0.3,random_state_value=42):\n",
        "    X = df.drop(columns=[column_to_predict])\n",
        "    y = df[column_to_predict]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_value, random_state=random_state_value)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def list_unique_values(df, column_name):\n",
        "    \"\"\"\n",
        "    Function to list all unique values in a given column of a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pandas DataFrame\n",
        "    - column_name: Name of the column to find unique values\n",
        "\n",
        "    Returns:\n",
        "    - A list of unique values in the specified column.\n",
        "    \"\"\"\n",
        "    if column_name not in df.columns:\n",
        "        raise ValueError(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
        "\n",
        "    unique_values = df[column_name].unique()\n",
        "    return unique_values\n",
        "\n",
        "\n",
        "# Function to calculate YearMade based on ModelID\n",
        "def calc_YearMade(df, model_id):\n",
        "    valid_years = df.loc[(df['ModelID'] == model_id) & (df['YearMade'] > 1000), 'YearMade']\n",
        "    return int(valid_years.mean()) if not valid_years.empty else 1000  # Default if no valid years exist\n",
        "\n",
        "def update_YearMade(df):\n",
        "  print(\"update_YearMade START\")\n",
        "  # Update YearMade where it is 1000\n",
        "  df.loc[df['YearMade'] == 1000, 'YearMade'] = df.loc[df['YearMade'] == 1000, 'ModelID'].apply(lambda model_id: calc_YearMade(df, model_id))\n",
        "  # Compute the mean excluding rows where YearMade == 1000\n",
        "  mean_yearmade = df.loc[df['YearMade'] != 1000, 'YearMade'].mean()\n",
        "\n",
        "  # Update all rows where YearMade == 1000 with the calculated mean\n",
        "  df.loc[df['YearMade'] == 1000, 'YearMade'] = int(round(mean_yearmade))\n",
        "\n",
        "  print(\"update_YearMade END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "def update_NaN_To_None_or_Unspecified(df):\n",
        "    \"\"\"\n",
        "    Updates NaN values to 'None or Unspecified' in columns where the value\n",
        "    'None or Unspecified' is already present.\n",
        "    \"\"\"\n",
        "    print(\"update_NaN_To_None_or_Unspecified START\")\n",
        "\n",
        "    update_to = 'None or Unspecified'\n",
        "\n",
        "    for col in df.columns:\n",
        "        unique_values = list_unique_values(df, col)  # Get unique values for the column\n",
        "\n",
        "        # Check if 'None or Unspecified' exists and if there are NaN values\n",
        "        if update_to in unique_values and pd.isnull(unique_values).any():\n",
        "            df[col] = df[col].fillna(update_to)  # Fill NaN with the specified value\n",
        "\n",
        "    print(\"update_NaN_To_None_or_Unspecified END\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def update_MachineHoursCurrentMeter(df):\n",
        "  print(\"update_MachineHoursCurrentMeter START\")\n",
        "\n",
        "  # Update the 'MachineHoursCurrentMeter' column: replace NaN or 0 with 0\n",
        "  column_name = 'MachineHoursCurrentMeter'\n",
        "\n",
        "  # Check if the column exists\n",
        "  if column_name in df.columns:\n",
        "      df[column_name] = df[column_name].fillna(0)  # Replace NaN with 0\n",
        "      df[column_name] = df[column_name].replace(0, 0)  # Ensure 0 stays 0\n",
        "      #print(f\"Updated '{column_name}' column successfully!\")\n",
        "  #else:\n",
        "      #print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n",
        "\n",
        "  print(\"update_MachineHoursCurrentMeter END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "def update_auctioneerID(df):\n",
        "  print(\"update_auctioneerID START\")\n",
        "\n",
        "  # Assuming 'df' is your DataFrame\n",
        "  # Fill null values in the 'auctioneerID' column with 100.0\n",
        "  if 'auctioneerID' in df.columns:\n",
        "      df['auctioneerID'] = df['auctioneerID'].fillna(100.0)\n",
        "      #print(\"'auctioneerID' null values filled with 100.0 successfully!\")\n",
        "  #else:\n",
        "  #    print(\"Column 'auctioneerID' does not exist in the DataFrame.\")\n",
        "  print(\"update_auctioneerID END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "def update_Enclosure(df):\n",
        "  print(\"update_Enclosure START\")\n",
        "\n",
        "  # Replace null values in the 'Enclosure' column with 'N/A'\n",
        "  if 'Enclosure' in df.columns:\n",
        "      df['Enclosure'] = df['Enclosure'].fillna('None or Unspecified')\n",
        "\n",
        "  print(\"update_Enclosure END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "def convert_date_columns(df, date_column):\n",
        "    \"\"\"\n",
        "    Convert date column into multiple numeric features like year, month, day, etc.\n",
        "    Handles potential issues like missing date_column or invalid data.\n",
        "    \"\"\"\n",
        "    print(\"convert_date_columns START\")\n",
        "\n",
        "    # Ensure the date_column exists in the DataFrame\n",
        "    if date_column not in df.columns:\n",
        "        raise KeyError(f\"Column '{date_column}' does not exist in the DataFrame.\")\n",
        "\n",
        "    # Convert the column to datetime\n",
        "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')  # Handle invalid date strings\n",
        "\n",
        "    # Check if any date values are invalid after conversion\n",
        "    if df[date_column].isnull().all():\n",
        "        raise ValueError(f\"All values in '{date_column}' could not be converted to datetime.\")\n",
        "\n",
        "    # Extract date features\n",
        "    df['year'] = df[date_column].dt.year\n",
        "    df['month'] = df[date_column].dt.month\n",
        "    df['day'] = df[date_column].dt.day\n",
        "    df['day_of_week'] = df[date_column].dt.dayofweek\n",
        "    df['is_weekend'] = df['day_of_week'] >= 5  # Saturday=5, Sunday=6\n",
        "\n",
        "    # Drop the original date column\n",
        "    df = df.drop(columns=[date_column])\n",
        "\n",
        "    print(\"convert_date_columns END\")\n",
        "\n",
        "    return df\n",
        "\n",
        "def encode_all_categories(df):\n",
        "  '''\n",
        "  Function to convert all string columns in a given DataFrame into categories.\n",
        "  '''\n",
        "  print(\"encode_all_categories START\")\n",
        "  for col in df.select_dtypes(['object']):\n",
        "    df[col] = df[col].astype('category')\n",
        "\n",
        "  for col in df.select_dtypes(['category']):\n",
        "    df[col] = df[col].cat.codes\n",
        "\n",
        "  print(\"encode_all_categories END\")\n",
        "\n",
        "  return df\n",
        "\n",
        "def prepare_dataframe(df_pre:pd.DataFrame):\n",
        "  '''04/02/2025 Start'''\n",
        "  df_pre=update_YearMade(df_pre)\n",
        "  print()\n",
        "  df_pre=update_NaN_To_None_or_Unspecified(df_pre)\n",
        "  print()\n",
        "\n",
        "  df_pre=update_MachineHoursCurrentMeter(df_pre)\n",
        "  print()\n",
        "\n",
        "  df_pre=update_auctioneerID(df_pre)\n",
        "  print()\n",
        "\n",
        "  df_pre=update_Enclosure(df_pre)\n",
        "  print()\n",
        "\n",
        "  df_pre=convert_date_columns(df_pre,'saledate')\n",
        "  print()\n",
        "\n",
        "  df_pre=encode_all_categories(df_pre)\n",
        "  '''04/02/2025 End'''\n",
        "\n",
        "  return df_pre\n",
        "\n",
        "def run_test(model):\n",
        "  file_path = \"/content/drive/My Drive/Valid.csv\"  # Replace with the saved file path\n",
        "  df_valid = pd.read_csv(file_path)\n",
        "  df_valid['SalePrice']=None\n",
        "  df_valid=prepare_dataframe(df_valid)\n",
        "  X = df_valid.drop(columns=['SalePrice'])\n",
        "  y = df_valid['SalePrice']\n",
        "  y = model.predict(X)\n",
        "\n",
        "  df_valid.loc[X.index, 'SalePrice'] = y\n",
        "\n",
        "  file_path = \"/content/drive/My Drive/output.csv\"  # Save to Google Drive root\n",
        "  df_valid[['SalesID', 'SalePrice']].to_csv(file_path, index=False)\n",
        "\n",
        "  print(f\"File saved successfully at: {file_path}\")\n",
        "\n",
        "def run_train():\n",
        "  pd.set_option('display.expand_frame_repr', False)\n",
        "  '''\n",
        "  df=load_dataframe_from_drive()\n",
        "  df = df.sample(n=10000, random_state=42)\n",
        "  df=prepare_dataframe(df)\n",
        "  model,xs=train_model(df=df,column_to_predict='SalePrice')\n",
        "  save_dataframe(df,'04022025_df')\n",
        "  save_model(model,'04022025_model')\n",
        "  '''\n",
        "\n",
        "  df=load_dataframe_from_drive('04022025_df')\n",
        "  model=load_model('04022025_model')\n",
        "  xs=generate_X_Y_params(df,'SalePrice')\n",
        "  return model,xs\n",
        "\n"
      ],
      "metadata": {
        "id": "-2nKvfNGzDz2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RUN CELL**"
      ],
      "metadata": {
        "id": "rhixEKWOyx_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Starting.....')\n",
        "model,xs=run_train()\n",
        "print('Testing...')\n",
        "run_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DE-fzHuyulv",
        "outputId": "0fe0f5af-5259-4592-ae23-cb954761584e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting.....\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f9bf011598fe>:17: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update_YearMade START\n",
            "update_YearMade END\n",
            "\n",
            "update_NaN_To_None_or_Unspecified START\n",
            "update_NaN_To_None_or_Unspecified END\n",
            "\n",
            "update_MachineHoursCurrentMeter START\n",
            "update_MachineHoursCurrentMeter END\n",
            "\n",
            "update_auctioneerID START\n",
            "update_auctioneerID END\n",
            "\n",
            "update_Enclosure START\n",
            "update_Enclosure END\n",
            "\n",
            "convert_date_columns START\n",
            "convert_date_columns END\n",
            "\n",
            "encode_all_categories START\n",
            "encode_all_categories END\n",
            "train_model START\n",
            "RMSE Baseline accuracy: 22932.4005340408\n",
            "Train RMSE: 2636.4997091339187\n",
            "Test RMSE: 7050.654203775603\n",
            "train_model END\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File saved successfully at: /content/drive/My Drive/04022025_df.csv\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model saved at /content/drive/My Drive/04022025_model.pkl\n",
            "Testing...\n",
            "update_YearMade START\n",
            "update_YearMade END\n",
            "\n",
            "update_NaN_To_None_or_Unspecified START\n",
            "update_NaN_To_None_or_Unspecified END\n",
            "\n",
            "update_MachineHoursCurrentMeter START\n",
            "update_MachineHoursCurrentMeter END\n",
            "\n",
            "update_auctioneerID START\n",
            "update_auctioneerID END\n",
            "\n",
            "update_Enclosure START\n",
            "update_Enclosure END\n",
            "\n",
            "convert_date_columns START\n",
            "convert_date_columns END\n",
            "\n",
            "encode_all_categories START\n",
            "encode_all_categories END\n",
            "File saved successfully at: /content/drive/My Drive/output.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f9bf011598fe>:261: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[54815.   66690.   35675.25 ... 10480.   12325.   21685.  ]' has dtype incompatible with int8, please explicitly cast to a compatible dtype first.\n",
            "  df_valid.loc[X.index, 'SalePrice'] = y\n"
          ]
        }
      ]
    }
  ]
}