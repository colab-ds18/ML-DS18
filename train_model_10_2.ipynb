{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8010320-6099-40a3-ab4d-9e043c68ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import necessary libraries due to execution reset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Define final categorization for Steering_Controls\n",
    "def categorize_steering_controls_final(value):\n",
    "    if value in [\"Four Wheel Standard\", \"Conventional\"]:\n",
    "        return \"Mid Price Steering\"\n",
    "    elif value in [\"Command Control\"]:\n",
    "        return \"High Price Steering\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "\n",
    "# Define price-based categories for Track_Type\n",
    "def categorize_track_type(value):\n",
    "    if value in [\"Rubber\"]:\n",
    "        return \"Low Price Track\"\n",
    "    elif value in [\"Steel\"]:\n",
    "        return \"High Price Track\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "# Define price-based categories for Transmission\n",
    "def categorize_transmission(value):\n",
    "    if value in [\"Powershuttle\", \"Standard\", \"Direct Drive\"]:\n",
    "        return \"Low Price Transmission\"\n",
    "    elif value in [\"Autoshift\", \"Hydrostatic\"]:\n",
    "        return \"Mid Price Transmission\"\n",
    "    elif value in [\"Powershift\", \"None or Unspecified\", \"AutoShift\"]:\n",
    "        return \"High Price Transmission\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "# Define price-based categories for Steering_Controls\n",
    "def categorize_steering_controls(value):\n",
    "    if value in [\"Four Wheel Standard\"]:\n",
    "        return \"Low Price Steering\"\n",
    "    elif value in [\"Conventional\"]:\n",
    "        return \"Mid Price Steering\"\n",
    "    elif value in [\"Command Control\"]:\n",
    "        return \"High Price Steering\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "\n",
    "# Define price-based categories for ProductGroup\n",
    "def categorize_product_group(price):\n",
    "    if price < 20000:\n",
    "        return \"Low Price Group\"\n",
    "    elif 20000 <= price < 40000:\n",
    "        return \"Mid Price Group\"\n",
    "    else:\n",
    "        return \"High Price Group\"\n",
    "\n",
    "\n",
    "def create_model_category_mapping(training_df):\n",
    "    \"\"\"\n",
    "    Creates a mapping of ModelID to Model_Category based on fiModelDesc and SalePrice in training data.\n",
    "    \n",
    "    Parameters:\n",
    "    training_df (pd.DataFrame): Training dataset containing fiModelDesc and SalePrice.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary mapping ModelID to Model_Category.\n",
    "    \"\"\"\n",
    "    # Compute average SalePrice per fiModelDesc in training data\n",
    "    model_avg_price = training_df.groupby(\"fiModelDesc\")[\"SalePrice\"].mean()\n",
    "    \n",
    "    # Define price categories\n",
    "    def categorize_price(price):\n",
    "        if price < 20000:\n",
    "            return \"Low Price Models\"\n",
    "        elif 20000 <= price < 60000:\n",
    "            return \"Mid Price Models\"\n",
    "        else:\n",
    "            return \"High Price Models\"\n",
    "    \n",
    "    # Map fiModelDesc to categories\n",
    "    model_category_mapping = model_avg_price.apply(categorize_price).to_dict()\n",
    "    \n",
    "    # Create ModelID to category mapping using fiModelDesc\n",
    "    training_df[\"Model_Category\"] = training_df[\"fiModelDesc\"].map(model_category_mapping)\n",
    "    modelid_to_category = training_df.set_index(\"ModelID\")[\"Model_Category\"].to_dict()\n",
    "    \n",
    "    return modelid_to_category, model_category_mapping\n",
    "\n",
    "def categorize_model_id(df, modelid_to_category, model_category_mapping):\n",
    "    \"\"\"\n",
    "    Categorizes ModelID based on precomputed price categories.\n",
    "    If ModelID is not found, falls back to fiModelDesc categorization.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing ModelID and fiModelDesc columns.\n",
    "    modelid_to_category (dict): Mapping of ModelID to Model_Category.\n",
    "    model_category_mapping (dict): Mapping of fiModelDesc to Model_Category for fallback.\n",
    "    \n",
    "    Returns:\n",
    "    pd.Series: A Series with categorized model price labels.\n",
    "    \"\"\"\n",
    "    df[\"Predicted_Model_Category\"] = df[\"ModelID\"].map(modelid_to_category)\n",
    "    \n",
    "    # Handle missing ModelID by checking fiModelDesc mapping\n",
    "    missing_mask = df[\"Predicted_Model_Category\"].isna()\n",
    "    df.loc[missing_mask, \"Predicted_Model_Category\"] = df.loc[missing_mask, \"fiModelDesc\"].map(model_category_mapping)\n",
    "    \n",
    "    # Handle any remaining missing values by assigning 'Unknown'\n",
    "    df[\"Predicted_Model_Category\"].fillna(\"Unknown\", inplace=True)\n",
    "    \n",
    "    return df[\"Predicted_Model_Category\"]\n",
    "\n",
    "\n",
    "\n",
    "def extract_horsepower(df):\n",
    "    \"\"\"\n",
    "    Extracts and imputes missing Horsepower values from fiProductClassDesc.\n",
    "    Optimized for performance using vectorized operations.\n",
    "    \"\"\"\n",
    "    def extract_numeric_range(value):\n",
    "        \"\"\"Extracts the average horsepower value from a range like '100 to 120 Horsepower'.\"\"\"\n",
    "        if pd.isna(value) or not isinstance(value, str):\n",
    "            return np.nan\n",
    "        numbers = re.findall(r'[\\d\\.]+', value)\n",
    "        if len(numbers) == 2:\n",
    "            return (float(numbers[0]) + float(numbers[1])) / 2\n",
    "        elif len(numbers) == 1:\n",
    "            return float(numbers[0])\n",
    "        return np.nan\n",
    "    \n",
    "    # Identify rows with Horsepower in fiProductClassDesc\n",
    "    mask_horsepower = df['fiProductClassDesc'].str.contains(\"Horsepower\", na=False)\n",
    "    \n",
    "    # Extract horsepower values\n",
    "    df.loc[mask_horsepower, 'Horsepower_Unit_Type'] = 'Horsepower'\n",
    "    df.loc[mask_horsepower, 'Extracted_Horsepower'] = df.loc[mask_horsepower, 'fiProductClassDesc'].apply(extract_numeric_range)\n",
    "    \n",
    "    # Handle 'Variable' and 'No' values in Engine_Horsepower\n",
    "    df.loc[df['Engine_Horsepower'].isin(['Variable', 'No']), 'Engine_Horsepower'] = np.nan\n",
    "    \n",
    "    # Impute missing Engine_Horsepower values where Extracted_Horsepower is available\n",
    "    df['Engine_Horsepower_Imputed'] = df['Engine_Horsepower'].combine_first(df['Extracted_Horsepower'])\n",
    "    \n",
    "    # Fill remaining NaN values with median horsepower\n",
    "    #df['Engine_Horsepower_Imputed'].fillna(df['Engine_Horsepower_Imputed'].median(), inplace=True)\n",
    "    df.drop(columns='Engine_Horsepower',inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_product_size(df):\n",
    "    \"\"\"\n",
    "    Function to preprocess and impute missing ProductSize values based on fiProductClassDesc.\n",
    "    \n",
    "    Steps:\n",
    "    1. Extract Product Type and Metric Tons / Horsepower from fiProductClassDesc.\n",
    "    2. Identify Unit Type (Metric Tons, Horsepower, or Lb Operating Capacity).\n",
    "    3. Convert Metric Tons / Horsepower to numerical values.\n",
    "    4. Use Metric Tons to impute missing ProductSize values.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Extract Product Type and Size Descriptor\n",
    "    def split_product_desc(desc):\n",
    "        if pd.isna(desc):\n",
    "            return pd.NA, pd.NA\n",
    "        match = re.search(r'(.+?)-\\s*([\\d\\.]+.*)', desc)\n",
    "        if match:\n",
    "            return match.group(1).strip(), match.group(2).strip()\n",
    "        return desc.strip(), pd.NA  # If no match, return full description as product\n",
    "    \n",
    "    df[['Product_Type', 'Metric_Tons_HP']] = df['fiProductClassDesc'].apply(lambda x: pd.Series(split_product_desc(x)))\n",
    "    \n",
    "    # Step 2: Identify Unit Type\n",
    "    def extract_unit_type(desc):\n",
    "        if pd.isna(desc):\n",
    "            return pd.NA\n",
    "        if \"Metric Tons\" in desc:\n",
    "            return \"Metric Tons\"\n",
    "        elif \"Horsepower\" in desc:\n",
    "            return \"Horsepower\"\n",
    "        elif \"Lb Operating Capacity\" in desc:\n",
    "            return \"Lb Operating Capacity\"\n",
    "        return pd.NA\n",
    "    \n",
    "    df[\"Unit_Type\"] = df[\"Metric_Tons_HP\"].apply(extract_unit_type)\n",
    "    \n",
    "    # Step 3: Convert Metric Tons to numerical values\n",
    "    def extract_numeric_range(value):\n",
    "        \"\"\"Extracts the average value from a range like '12.0 to 14.0 Metric Tons'.\"\"\"\n",
    "        if pd.isna(value) or not isinstance(value, str):\n",
    "            return np.nan\n",
    "        numbers = re.findall(r'[\\d\\.]+', value)\n",
    "        if len(numbers) == 2:  # If range exists, take the average\n",
    "            return (float(numbers[0]) + float(numbers[1])) / 2\n",
    "        elif len(numbers) == 1:  # If only one number exists, use it\n",
    "            return float(numbers[0])\n",
    "        return np.nan\n",
    "    \n",
    "    df['Metric_Tons_Value'] = df['Metric_Tons_HP'].apply(lambda x: extract_numeric_range(x) if isinstance(x, str) else np.nan)\n",
    "    \n",
    "    # Step 4: Impute missing ProductSize values using Metric Tons\n",
    "    def impute_product_size(row):\n",
    "        if pd.isna(row['ProductSize']) and not pd.isna(row['Metric_Tons_Value']) and (row['Metric_Tons_Value']=='Metric Tons'):\n",
    "            if row['Metric_Tons_Value']  <= 5:\n",
    "                return 'Mini'\n",
    "            elif 5 < row['Metric_Tons_Value'] <= 75:\n",
    "                return 'Compact'\n",
    "            elif 20 < row['Metric_Tons_Value'] <= 50:\n",
    "                return 'Large / Medium'\n",
    "            elif 75 < row['Metric_Tons_Value'] <= 200:\n",
    "                return 'Medium'\n",
    "            elif row['Metric_Tons_Value'] > 200:\n",
    "                return 'Large'\n",
    "        return row['ProductSize']\n",
    "    \n",
    "    df['ProductSize_Imputed'] = df.apply(impute_product_size, axis=1)\n",
    "    df.drop(columns=['ProductSize','Metric_Tons_Value','Metric_Tons_HP','Unit_Type'],inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    return df\n",
    "def Enclosure_fun(df):\n",
    "    list1=['EROPS','OROPS','EROPS AC']\n",
    "    list2=['NO ROPS','None or Unspecified']\n",
    "    df['Enclosure_cat']=0\n",
    "    df.loc[df['Enclosure'].isin(list1), 'Enclosure_cat'] = 1\n",
    "    df.loc[df['Enclosure'].isin(list2), 'Enclosure_cat'] = 0\n",
    "    df.loc[df['Enclosure']=='EROPS w AC','Enclosure_cat']=2\n",
    "    df.drop(columns='Enclosure',inplace=True)\n",
    "    return df\n",
    "# Define categories based on observed price trends\n",
    "def categorize_hydraulics(value):\n",
    "    if value in [\"Missing\", \"Auxiliary\", \"Standard\"]:\n",
    "        return \"Basic\"\n",
    "    elif value in [\"2 Valve\", \"None or Unspecified\", \"3 Valve\"]:\n",
    "        return \"Mid-Level\"\n",
    "    else:\n",
    "        return \"Advanced\"\n",
    "\n",
    "\n",
    "\n",
    "# Reload the dataset\n",
    "ProductSize_path=r'C:\\Users\\eitanb\\Documents\\DS\\ML\\ML_project\\DATA/ProductSize_Null_fix_model.pkl'\n",
    "file_path_train = r\"C:\\Users\\eitanb\\Documents\\DS\\ML\\ML_project\\DATA/Train.csv\"\n",
    "df = pd.read_csv(file_path_train)[['SalesID', 'SalePrice',  'ModelID',\n",
    "        'YearMade', 'MachineHoursCurrentMeter', 'UsageBand',\n",
    "       'saledate', 'ProductSize',\n",
    "       'fiProductClassDesc', 'state', 'ProductGroup', \n",
    "       'Drive_System', 'Enclosure', \n",
    "        'Transmission', 'Turbocharged',  'Engine_Horsepower', 'Hydraulics',\n",
    "         'Tire_Size',\n",
    "       'Track_Type',\n",
    "       'Travel_Controls', 'Differential_Type', 'Steering_Controls','fiModelDesc']]\n",
    "\n",
    "# Convert 'saledate' to datetime and extract year, month, and day\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce')\n",
    "df['sale_year'] = df['saledate'].dt.year\n",
    "df['sale_month'] = df['saledate'].dt.month\n",
    "df['sale_day'] = df['saledate'].dt.day\n",
    "\n",
    "# Apply categorization\n",
    "df[\"Hydraulics_Category\"] = df[\"Hydraulics\"].apply(categorize_hydraulics)\n",
    "# Apply categorization\n",
    "df[\"Steering_Controls_Category\"] = df[\"Steering_Controls\"].apply(categorize_steering_controls)\n",
    "# Apply categorization\n",
    "df[\"Transmission_Category\"] = df[\"Transmission\"].apply(categorize_transmission)\n",
    "\n",
    "# Apply categorization\n",
    "df[\"Steering_Controls_Category\"] = df[\"Steering_Controls\"].apply(categorize_steering_controls_final)\n",
    "\n",
    "df=Enclosure_fun(df)\n",
    "df=extract_horsepower(df)\n",
    "\n",
    "# Create mappings from training data only in saleprice \n",
    "modelid_to_category, model_category_mapping = create_model_category_mapping(df) # need to upload the modelid_to_category, model_category_mapping in the test\n",
    "\n",
    "# Apply categorization to test data\n",
    "df[\"Predicted_Model_Category\"] = categorize_model_id(df, modelid_to_category, model_category_mapping) # need to upload the modelid_to_category, model_category_mapping in the test\n",
    "\n",
    "# Compute the average price for each ProductGroup\n",
    "# Apply categorization\n",
    "df[\"Track_Type_Category\"] = df[\"Track_Type\"].apply(categorize_track_type)\n",
    "\n",
    "product_group_avg_price = df.groupby(\"ProductGroup\")[\"SalePrice\"].mean()\n",
    "\n",
    "# Map each ProductGroup to a price category\n",
    "df[\"ProductGroup_Category\"] = df[\"ProductGroup\"].map(product_group_avg_price).apply(categorize_product_group) # need to upload the categorize_product_group in the test\n",
    "df=preprocess_product_size(df)\n",
    "\n",
    "# Define function to update 'YearMade' and create 'YearMade_Bucket'\n",
    "def update_YearMade(df):\n",
    "    print(\"update_YearMade START\")\n",
    "    \n",
    "    # Compute median YearMade for each ModelID\n",
    "    model_medians = df.loc[df['YearMade'] > 1000].groupby('ModelID')['YearMade'].median()\n",
    "    \n",
    "    # Update YearMade where it is 1000 using ModelID median\n",
    "    df.loc[df['YearMade'] == 1000, 'YearMade'] = df['ModelID'].map(model_medians)\n",
    "    \n",
    "    # Compute overall median YearMade excluding 1000 values\n",
    "    overall_median = df.loc[df['YearMade'] > 1000, 'YearMade'].median()\n",
    "    \n",
    "    # Replace any remaining 1000 values with overall median\n",
    "    df['YearMade'].fillna(overall_median, inplace=True)\n",
    "        \n",
    "    # Bucketize YearMade\n",
    "    bins = [0, 1980, 1995, 2005, 2010, 2025]\n",
    "    labels = [\"Before 1980\", \"1980-1995\", \"1996-2005\", \"2006-2010\", \"2011-2025\"]\n",
    "    df['YearMade_Bucket'] = pd.cut(df['YearMade'], bins=bins, labels=labels, right=True)\n",
    "    \n",
    "    print(\"update_YearMade END\")\n",
    "    return df\n",
    "\n",
    "# Apply YearMade update\n",
    "df = update_YearMade(df)\n",
    "\n",
    "#df.drop(columns=['fiProductClassDesc','Hydraulics','fiSecondaryDesc','auctioneerID','fiModelDesc','fiBaseModel','ProductGroupDesc','MachineID','ProductGroup'],inplace=True)\n",
    "\n",
    "\n",
    "# Filter dataset to only include the last 5 years\n",
    "recent_years = df['sale_year'].dropna().unique()\n",
    "recent_years.sort()\n",
    "#selected_years = recent_years[-5:]\n",
    "#df_filtered = df[df['sale_year'].isin(selected_years)]\n",
    "df_filtered=df.copy()\n",
    "\n",
    "# Drop irrelevant columns: 'SalesID', 'saledate'\n",
    "high_cardinality_cols = [col for col in df_filtered.select_dtypes(include=['object']).columns if df_filtered[col].nunique() > 50]\n",
    "df_filtered = df_filtered.drop(columns=['SalesID', 'saledate'] + high_cardinality_cols, errors='ignore')\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df_filtered.select_dtypes(include=['object']).columns\n",
    "\n",
    "df_filtered[\"YearMade_Bucket\"] = df_filtered[\"YearMade_Bucket\"].astype(str).fillna(\"Unknown\")\n",
    "\n",
    "# Define category order and apply Ordinal Encoding\n",
    "year_bucket_encoder = OrdinalEncoder(\n",
    "    categories=[[\"Before 1980\", \"1980-1995\", \"1996-2005\", \"2006-2010\", \"2011-2025\", \"Unknown\"]],\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1\n",
    ")\n",
    "\n",
    "df_filtered[\"YearMade_Bucket\"] = year_bucket_encoder.fit_transform(df_filtered[[\"YearMade_Bucket\"]])\n",
    "# Apply Ordinal Encoding to 'YearMade_Bucket'\n",
    "#year_bucket_encoder = OrdinalEncoder(categories=[[\"Before 1980\", \"1980-1995\", \"1996-2005\", \"2006-2010\", \"2011-2025\"]])\n",
    "#df_filtered[\"YearMade_Bucket\"] = year_bucket_encoder.fit_transform(df_filtered[[\"YearMade_Bucket\"]])\n",
    "\n",
    "# Identify high, moderate, and low cardinality categorical columns\n",
    "high_cardinality_cols = [col for col in categorical_cols if df_filtered[col].nunique() >= 50]\n",
    "moderate_cardinality_cols = [col for col in categorical_cols if 10 <= df_filtered[col].nunique() < 50]\n",
    "low_cardinality_cols = [col for col in categorical_cols if df_filtered[col].nunique() < 10]\n",
    "\n",
    "# Fill missing categorical values with \"Unknown\"\n",
    "for col in categorical_cols:\n",
    "    df_filtered[col] = df_filtered[col].fillna(\"Unknown\")\n",
    "\n",
    "# Encoding strategy\n",
    "\n",
    "# Apply One-Hot Encoding (OHE) to low-cardinality categories\n",
    "df_encoded = pd.get_dummies(df_filtered, columns=low_cardinality_cols, drop_first=True)\n",
    "\n",
    "# Apply Ordinal Encoding to moderate-cardinality categories\n",
    "if moderate_cardinality_cols:\n",
    "    ord_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "    df_encoded[moderate_cardinality_cols] = ord_encoder.fit_transform(df_encoded[moderate_cardinality_cols])\n",
    "\n",
    "# Apply Frequency Encoding to high-cardinality categories\n",
    "for col in high_cardinality_cols:\n",
    "    freq_encoding = df_encoded[col].value_counts().to_dict()\n",
    "    df_encoded[col] = df_encoded[col].map(freq_encoding)\n",
    "\n",
    "# Drop rows with missing SalePrice (target variable)\n",
    "df_encoded = df_encoded.dropna(subset=['SalePrice'])\n",
    "\n",
    "# Split into features and target\n",
    "X = df_encoded.drop(columns=['SalePrice'])\n",
    "y = df_encoded['SalePrice']\n",
    "\n",
    "# Split data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "# Display model performance\n",
    "mae, rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
